# Mini-LLaDA

A lightweight implementation of [Large Language Diffusion Models (LLDMs)](https://github.com/ML-GSAI/LLaDA) based on [Llama2](https://github.com/karpathy/llama2.c).

## ğŸ›  Installation
```bash
# Clone the repository
git clone https://github.com/NiklasDob/Mini-LLaDA.git
cd Mini-LLaDA

# Install dependencies
pip install -r requirements.txt
```
## ğŸ“Š Training

Train the model using Shakespeare dataset:
```bash
$ python train.py --dataset shakespeare  # or enwik8
```

## ğŸ“ Text Generation

Generate text based on a given prompt:
```bash
$ python generate.py
  Enter your prompt:
```

## ğŸ“‚ Structure
```
Mini-LLaDA/
â”‚â”€â”€ data/                   # Datasets (tokenized text)                      
â”œâ”€â”€ model.py                # Llama 2 model for the diffusion objective  
â”œâ”€â”€ generate.py             # Test trained models to generate based on a prompt  
â”œâ”€â”€ train.py                # Train the model on a given dataset (shakespeare or enwik8)  
â”‚â”€â”€ README.md               # Project documentation  
â”‚â”€â”€ requirements.txt        # Dependencies  
```
## License
MIT